{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 00:13:39,498 - INFO - Created directory: data/1_updated/batch1\n",
      "2024-07-05 00:13:39,499 - INFO - Created directory: data/1_updated/batch1/temp\n",
      "2024-07-05 00:13:40,631 - INFO - \n",
      "2024-07-05 00:13:42,099 - INFO - \n",
      "2024-07-05 00:13:44,422 - INFO - \n",
      "2024-07-05 00:13:47,121 - INFO - PLINK v1.90b7.2 64-bit (11 Dec 2023)           www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1.log.\n",
      "Options in effect:\n",
      "  --bfile data/Raw_data/batch1\n",
      "  --make-bed\n",
      "  --out data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1\n",
      "  --update-chr\n",
      "  --update-map data/strand_files/HumanOmni2-5Exome-8-v1-1-A-strand-b37/HumanOmni2-5Exome-8-v1-1-A-b37.strand.chr\n",
      "\n",
      "Note: --update-map <filename> + parameter-free --update-chr deprecated.  Use\n",
      "--update-chr <filename> instead.\n",
      "65536 MB RAM detected; reserving 32768 MB for main workspace.\n",
      "2546527 variants loaded from .bim file.\n",
      "1541 people (836 males, 683 females, 22 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1.nosex .\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1541 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is 0.987338.\n",
      "2546527 variants and 1541 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--update-chr: 2546199 values updated, 37116 variant IDs not present.\n",
      "--make-bed to data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1.bed +\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1.bim +\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1.fam ... 1010111112121313141415151616171718181919202021212222232324242525262627272828292930303131323233333434353536363737383839394040414142424343444445454646474748484949505051515252535354545555565657575858595960606161626263636464656566666767686869697070717172727373747475757676777778787979808081818282838384848585868687878888898990909191929293939494959596969797989899done.\n",
      "\n",
      "2024-07-05 00:13:50,158 - INFO - PLINK v1.90b7.2 64-bit (11 Dec 2023)           www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2.log.\n",
      "Options in effect:\n",
      "  --bfile data/1_updated/batch1/temp/TEMP_FILE_XX72262628_1\n",
      "  --make-bed\n",
      "  --out data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2\n",
      "  --update-map data/strand_files/HumanOmni2-5Exome-8-v1-1-A-strand-b37/HumanOmni2-5Exome-8-v1-1-A-b37.strand.pos\n",
      "\n",
      "65536 MB RAM detected; reserving 32768 MB for main workspace.\n",
      "2546527 variants loaded from .bim file.\n",
      "1541 people (836 males, 683 females, 22 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2.nosex .\n",
      "--update-map: 2546199 values updated, 37116 variant IDs not present.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1541 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is 0.987336.\n",
      "2546527 variants and 1541 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2.bed +\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2.bim +\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2.fam ... 1010111112121313141415151616171718181919202021212222232324242525262627272828292930303131323233333434353536363737383839394040414142424343444445454646474748484949505051515252535354545555565657575858595960606161626263636464656566666767686869697070717172727373747475757676777778787979808081818282838384848585868687878888898990909191929293939494959596969797989899done.\n",
      "\n",
      "2024-07-05 00:13:52,749 - INFO - PLINK v1.90b7.2 64-bit (11 Dec 2023)           www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3.log.\n",
      "Options in effect:\n",
      "  --bfile data/1_updated/batch1/temp/TEMP_FILE_XX72262628_2\n",
      "  --flip data/strand_files/HumanOmni2-5Exome-8-v1-1-A-strand-b37/HumanOmni2-5Exome-8-v1-1-A-b37.strand.flip\n",
      "  --make-bed\n",
      "  --out data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3\n",
      "\n",
      "65536 MB RAM detected; reserving 32768 MB for main workspace.\n",
      "2546527 variants loaded from .bim file.\n",
      "1541 people (836 males, 683 females, 22 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3.nosex .\n",
      "--flip: 1272859 SNPs flipped, 18631 SNP IDs not present.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1541 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is 0.987336.\n",
      "2546527 variants and 1541 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3.bed +\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3.bim +\n",
      "data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3.fam ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "\n",
      "2024-07-05 00:13:55,525 - INFO - PLINK v1.90b7.2 64-bit (11 Dec 2023)           www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/1_updated/batch1/updated.log.\n",
      "Options in effect:\n",
      "  --bfile data/1_updated/batch1/temp/TEMP_FILE_XX72262628_3\n",
      "  --extract data/strand_files/HumanOmni2-5Exome-8-v1-1-A-strand-b37/HumanOmni2-5Exome-8-v1-1-A-b37.strand.pos\n",
      "  --make-bed\n",
      "  --out data/1_updated/batch1/updated\n",
      "\n",
      "65536 MB RAM detected; reserving 32768 MB for main workspace.\n",
      "2546527 variants loaded from .bim file.\n",
      "1541 people (836 males, 683 females, 22 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to data/1_updated/batch1/updated.nosex .\n",
      "--extract: 2546199 variants remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 1541 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is 0.987336.\n",
      "2546199 variants and 1541 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to data/1_updated/batch1/updated.bed +\n",
      "data/1_updated/batch1/updated.bim + data/1_updated/batch1/updated.fam ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "\n",
      "2024-07-05 00:13:55,583 - INFO - Process completed successfully.\n",
      "2024-07-05 00:13:55,583 - INFO - Created directory: data/2_updated_rsids/batch1\n",
      "2024-07-05 00:13:56,444 - INFO - PLINK v2.00a5.12 M1 (25 Jun 2024)              www.cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/2_updated_rsids/batch1/batch1.log.\n",
      "Options in effect:\n",
      "  --bfile data/1_updated/batch1/updated\n",
      "  --make-bed\n",
      "  --out data/2_updated_rsids/batch1/batch1\n",
      "  --update-name data/strand_files/HumanOmni2-5Exome-8-v1-1-A-strand-b37/HumanOmni25Exome-8v1-1_A_rsids.txt\n",
      "\n",
      "Start time: Fri Jul  5 00:13:55 2024\n",
      "65536 MiB RAM detected; reserving 32768 MiB for main workspace.\n",
      "Using up to 16 threads (change this with --threads).\n",
      "1541 samples (683 females, 836 males, 22 ambiguous; 1541 founders) loaded from\n",
      "data/1_updated/batch1/updated.fam.\n",
      "2546199 variants loaded from data/1_updated/batch1/updated.bim.\n",
      "Note: No phenotype data present.\n",
      "--update-name: 2546199 values updated, 37453 variant IDs not present.\n",
      "Writing data/2_updated_rsids/batch1/batch1.fam ... done.\n",
      "Writing data/2_updated_rsids/batch1/batch1.bim ... done.\n",
      "Writing data/2_updated_rsids/batch1/batch1.bed ... 1012151820232528303336384143464851545659616466697274777982848790929597done.\n",
      "End time: Fri Jul  5 00:13:56 2024\n",
      "\n",
      "2024-07-05 00:13:56,444 - INFO - RS IDs updated successfully for data/2_updated_rsids/batch1/batch1\n",
      "2024-07-05 00:13:56,446 - INFO - Duplicate FID-IID pairs identified and written to data/2_updated_rsids/batch1/batch1_duplicate_iids.txt\n",
      "2024-07-05 00:13:56,446 - INFO - Created directory: data/3_removed_duplicates/batch1\n",
      "2024-07-05 00:13:56,953 - INFO - PLINK v2.00a5.12 M1 (25 Jun 2024)              www.cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/3_removed_duplicates/batch1/batch1_no_duplicates.log.\n",
      "Options in effect:\n",
      "  --bfile data/2_updated_rsids/batch1/batch1\n",
      "  --make-bed\n",
      "  --out data/3_removed_duplicates/batch1/batch1_no_duplicates\n",
      "  --remove data/2_updated_rsids/batch1/batch1_duplicate_iids.txt\n",
      "\n",
      "Start time: Fri Jul  5 00:13:56 2024\n",
      "65536 MiB RAM detected; reserving 32768 MiB for main workspace.\n",
      "Using up to 16 threads (change this with --threads).\n",
      "1541 samples (683 females, 836 males, 22 ambiguous; 1541 founders) loaded from\n",
      "data/2_updated_rsids/batch1/batch1.fam.\n",
      "2546199 variants loaded from data/2_updated_rsids/batch1/batch1.bim.\n",
      "Note: No phenotype data present.\n",
      "--remove: 1410 samples remaining.\n",
      "1410 samples (621 females, 767 males, 22 ambiguous; 1410 founders) remaining\n",
      "after main filters.\n",
      "Writing data/3_removed_duplicates/batch1/batch1_no_duplicates.fam ... done.\n",
      "Writing data/3_removed_duplicates/batch1/batch1_no_duplicates.bim ... done.\n",
      "Writing data/3_removed_duplicates/batch1/batch1_no_duplicates.bed ... 1012151820232528303336384143464851545659616466697274777982848790929597done.\n",
      "End time: Fri Jul  5 00:13:56 2024\n",
      "\n",
      "2024-07-05 00:13:56,954 - INFO - Duplicate samples removed successfully for data/3_removed_duplicates/batch1/batch1_no_duplicates\n",
      "2024-07-05 00:13:56,954 - INFO - Converting BED to VCF: data/3_removed_duplicates/batch1/batch1_no_duplicates.bed, data/3_removed_duplicates/batch1/batch1_no_duplicates.bim, data/3_removed_duplicates/batch1/batch1_no_duplicates.fam\n",
      "2024-07-05 00:13:56,955 - INFO - Created directory: data/4_vcf_outputs/batch1\n",
      "2024-07-05 00:13:57,867 - INFO - PLINK v2.00a5.12 M1 (25 Jun 2024)              www.cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to sorted.log.\n",
      "Options in effect:\n",
      "  --make-pgen\n",
      "  --merge-x\n",
      "  --out sorted\n",
      "  --pgen data/3_removed_duplicates/batch1/batch1_no_duplicates.bed\n",
      "  --psam data/3_removed_duplicates/batch1/batch1_no_duplicates.fam\n",
      "  --pvar data/3_removed_duplicates/batch1/batch1_no_duplicates.bim\n",
      "  --snps-only just-acgt\n",
      "  --sort-vars\n",
      "\n",
      "Start time: Fri Jul  5 00:13:56 2024\n",
      "65536 MiB RAM detected; reserving 32768 MiB for main workspace.\n",
      "Using up to 16 threads (change this with --threads).\n",
      "1410 samples (621 females, 767 males, 22 ambiguous; 1410 founders) loaded from\n",
      "data/3_removed_duplicates/batch1/batch1_no_duplicates.fam.\n",
      "2546030 out of 2546199 variants loaded from\n",
      "data/3_removed_duplicates/batch1/batch1_no_duplicates.bim.\n",
      "Note: No phenotype data present.\n",
      "2546030 variants remaining after main filters.\n",
      "Writing sorted.pvar ... done.\n",
      "Writing sorted.psam ... done.\n",
      "Writing sorted.pgen ... 1012151820232528303336384143464851545659616466697274777982848790929597done.\n",
      "End time: Fri Jul  5 00:13:57 2024\n",
      "\n",
      "2024-07-05 00:14:08,316 - INFO - PLINK v2.00a5.12 M1 (25 Jun 2024)              www.cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/4_vcf_outputs/batch1/batch1.log.\n",
      "Options in effect:\n",
      "  --export vcf id-paste=iid bgz\n",
      "  --fa data/ref_37/human_g1k_v37.fasta.gz\n",
      "  --out data/4_vcf_outputs/batch1/batch1\n",
      "  --output-chr chrM\n",
      "  --pfile sorted\n",
      "  --ref-from-fa\n",
      "\n",
      "Start time: Fri Jul  5 00:13:57 2024\n",
      "65536 MiB RAM detected; reserving 32768 MiB for main workspace.\n",
      "Using up to 16 threads (change this with --threads).\n",
      "1410 samples (621 females, 767 males, 22 ambiguous; 1410 founders) loaded from\n",
      "sorted.psam.\n",
      "2546030 variants loaded from sorted.pvar.\n",
      "Note: No phenotype data present.\n",
      "--ref-from-fa: 391629 variants changed, 2152721 validated.\n",
      "--fa: Lengths scraped for 25 contigs.\n",
      "--export vcf bgz to data/4_vcf_outputs/batch1/batch1.vcf.gz ... 101011111212131314141515161617171818192020212122222323242425252626272728282930303131323233333434353536363737383839404041414242434344444545464647474848495050515152525353545455555656575758585960606161626263636464656566666767686869707071717272737374747575767677777878798080818182828383848485858686878788888990909191929293939494959596969797989899done.\n",
      "End time: Fri Jul  5 00:14:08 2024\n",
      "\n",
      "2024-07-05 00:14:08,329 - INFO - \n",
      "2024-07-05 00:14:08,329 - INFO - VCF file generated successfully: data/4_vcf_outputs/batch1/batch1.vcf.gz\n",
      "2024-07-05 00:14:08,330 - INFO - Starting indexing data/4_vcf_outputs/batch1/batch1.vcf.gz\n",
      "2024-07-05 00:14:21,049 - INFO - \n",
      "2024-07-05 00:14:21,050 - INFO - Indexing completed for VCF file: data/4_vcf_outputs/batch1/batch1.vcf.gz\n",
      "2024-07-05 00:14:21,050 - INFO - Creating frequency file for: data/4_vcf_outputs/batch1/batch1.vcf.gz\n",
      "2024-07-05 00:18:26,281 - INFO - \n",
      "2024-07-05 00:18:26,289 - INFO - \n",
      "2024-07-05 00:18:26,293 - ERROR - Error parsing CSV file: Error tokenizing data. C error: Expected 1 fields in line 31, saw 1419\n",
      "\n",
      "2024-07-05 00:18:26,293 - INFO - Frequency plots data: {}\n",
      "2024-07-05 00:18:26,294 - INFO - Created directory: data/5_liftover/batch1\n",
      "2024-07-05 00:18:26,294 - INFO - Directory already exists: data/5_liftover/batch1\n",
      "2024-07-05 00:18:26,380 - INFO - \n",
      "2024-07-05 00:18:26,380 - INFO - Liftover completed successfully for data/4_vcf_outputs/batch1/batch1.vcf.gz\n",
      "2024-07-05 00:18:26,381 - INFO - Liftover outputs: {'batch1': 'data/5_liftover/batch1/batch1.bcf'}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# 1 Update build - using strand files - should all be TOP and GRCh37. \n",
    "# 2 Update the rsid's - using Illumina rsid files (The batches have ids from Illumina). Running bim_build_and_chip_check.py should confirm\n",
    "# 3 Update SEX of the IIDs (using the NOPHO sex file)\n",
    "# 4 Identify duplicate IIDs in the files, write to file and remove with plink2 (Maybe keep first)\n",
    "# 5 Run a simple QC\n",
    "# 6 Create VCF files from plink files. \n",
    "# 7 liftover VCF files to GRCh38\n",
    "# 8 Create frequency files from liftover VCF\n",
    "# 9 \n",
    "\n",
    "\n",
    "# TODO \n",
    "# does the org plink files have a reference? different versions GRCh37/b37 and Hg19  https://gatk.broadinstitute.org/hc/en-us/articles/360035890951-Human-genome-reference-builds-GRCh38-or-hg38-b37-hg19\n",
    "# if so, use that for liftover\n",
    "# if not, use the hs37-1kg reference panel for liftover\n",
    "\n",
    "# We likly need to add some plink commands:\n",
    "# --keep-allele-order Use this EVERY SINGLE TIME you call a plink command, otherwise the order of Allele1 and Allele2 may (or probably will) be flipped in your data. \\\n",
    "# --allow-no-sex PLINK will default to removing individuals that have unassigned sex, use this to force it to keep them. \\\n",
    "# --snps-only Removes indels from your variant data and keeps only snps \\\n",
    "# --biallelic-only Removes sites with 2+ alleles \\\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Runs a shell command and logs the output.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            command, shell=True, check=True, text=True, capture_output=True\n",
    "        )\n",
    "        logging.info(result.stdout)\n",
    "        return True, result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(\n",
    "            f\"Command '{e.cmd}' returned non-zero exit status {e.returncode}. Error: {e.stderr}\"\n",
    "        )\n",
    "        return False, e.stderr\n",
    "\n",
    "\n",
    "def create_directory(directory):\n",
    "    \"\"\"Creates a directory if it does not exist.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            logging.info(f\"Created directory: {directory}\")\n",
    "        else:\n",
    "            logging.info(f\"Directory already exists: {directory}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create directory {directory}: {e}\")\n",
    "\n",
    "\n",
    "def update_build(batch_prefix, strand_file, output_dir):\n",
    "    \"\"\"Updates build using strand file and PLINK.\"\"\"\n",
    "    create_directory(output_dir)\n",
    "    temp_dir = os.path.join(output_dir, \"temp\")\n",
    "    create_directory(temp_dir)\n",
    "\n",
    "    temp_prefix = os.path.join(temp_dir, \"TEMP_FILE_XX72262628_\")\n",
    "    chr_file = f\"{strand_file}.chr\"\n",
    "    pos_file = f\"{strand_file}.pos\"\n",
    "    flip_file = f\"{strand_file}.flip\"\n",
    "\n",
    "    run_command(f\"cut -f 1,2 {strand_file} > {chr_file}\")\n",
    "    run_command(f\"cut -f 1,3 {strand_file} > {pos_file}\")\n",
    "    run_command(\n",
    "        f\"awk '{{if ($5==\\\"-\\\") print $0}}' {strand_file} | cut -f 1 > {flip_file}\"\n",
    "    )\n",
    "\n",
    "    commands = [\n",
    "        f\"plink --bfile {batch_prefix} --update-map {chr_file} --update-chr --make-bed --out {temp_prefix}1\",\n",
    "        f\"plink --bfile {temp_prefix}1 --update-map {pos_file} --make-bed --out {temp_prefix}2\",\n",
    "        f\"plink --bfile {temp_prefix}2 --flip {flip_file} --make-bed --out {temp_prefix}3\",\n",
    "        f\"plink --bfile {temp_prefix}3 --extract {pos_file} --make-bed --out {os.path.join(output_dir, 'updated')}\",\n",
    "    ]\n",
    "\n",
    "    for cmd in commands:\n",
    "        run_command(cmd)\n",
    "\n",
    "    # Cleanup temporary files\n",
    "    for file in [f\"{temp_prefix}{i}\" for i in range(1, 4)]:\n",
    "        for ext in [\".bed\", \".bim\", \".fam\", \".log\", \".nosex\"]:\n",
    "            try:\n",
    "                os.remove(file + ext)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "    logging.info(\"Process completed successfully.\")\n",
    "    return os.path.join(output_dir, \"updated\")\n",
    "\n",
    "\n",
    "def update_rsids(input_prefix, output_prefix, rsid_data):\n",
    "    \"\"\"Updates RS IDs using PLINK.\"\"\"\n",
    "    output_dir = os.path.dirname(output_prefix)\n",
    "    create_directory(output_dir)  # Ensure the directory exists\n",
    "    success, _ = run_command(\n",
    "        f\"plink2 --bfile {input_prefix} --update-name {rsid_data} --make-bed --out {output_prefix}\"\n",
    "    )\n",
    "    if success and all(\n",
    "        os.path.exists(f\"{output_prefix}.{ext}\") for ext in [\"bed\", \"bim\", \"fam\"]\n",
    "    ):\n",
    "        logging.info(f\"RS IDs updated successfully for {output_prefix}\")\n",
    "        return output_prefix\n",
    "    else:\n",
    "        logging.error(f\"Failed to update RS IDs for {output_prefix}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def identify_duplicate_iids(input_prefix):\n",
    "    fam_file = f\"{input_prefix}.fam\"\n",
    "    duplicates_file = f\"{input_prefix}_duplicate_iids.txt\"\n",
    "\n",
    "    if not os.path.exists(fam_file):\n",
    "        logging.error(f\"File not found: {fam_file}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(fam_file, \"r\") as file:\n",
    "            family_data = [line.strip().split()[:2] for line in file.readlines()]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading file {fam_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "    iid_to_fids = collections.defaultdict(list)\n",
    "    for fid, iid in family_data:\n",
    "        iid_to_fids[iid].append(fid)\n",
    "\n",
    "    duplicates = [\n",
    "        (fid, iid) for iid, fids in iid_to_fids.items() for fid in fids if len(fids) > 1\n",
    "    ]\n",
    "\n",
    "    if duplicates:\n",
    "        try:\n",
    "            with open(duplicates_file, \"w\") as file:\n",
    "                file.write(\"#FID\\tIID\\n\")\n",
    "                for fid, iid in duplicates:\n",
    "                    file.write(f\"{fid}\\t{iid}\\n\")\n",
    "            logging.info(\n",
    "                f\"Duplicate FID-IID pairs identified and written to {duplicates_file}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error writing duplicates file {duplicates_file}: {e}\")\n",
    "        return duplicates_file\n",
    "    else:\n",
    "        logging.warning(f\"No duplicate IIDs found in {input_prefix}.fam\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def remove_duplicate_samples(input_prefix, output_prefix):\n",
    "    duplicates_file = identify_duplicate_iids(input_prefix)\n",
    "    if duplicates_file:\n",
    "        output_dir = os.path.dirname(output_prefix)\n",
    "        create_directory(output_dir)  # Ensure the directory exists\n",
    "        remove_command = f\"plink2 --bfile {input_prefix} --remove {duplicates_file} --make-bed --out {output_prefix}\"\n",
    "        success, message = run_command(remove_command)\n",
    "        if success:\n",
    "            logging.info(f\"Duplicate samples removed successfully for {output_prefix}\")\n",
    "            return output_prefix\n",
    "        else:\n",
    "            logging.error(f\"Failed to remove duplicate samples for {output_prefix}: {message}\")\n",
    "            return None\n",
    "    else:\n",
    "        logging.error(f\"No duplicate IIDs identified for {input_prefix}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_duplicate_samples(fam_file):\n",
    "    \"\"\"Checks for duplicate sample names in the .fam file.\"\"\"\n",
    "    with open(fam_file, \"r\") as file:\n",
    "        samples = [line.strip().split()[1] for line in file]\n",
    "    duplicates = [\n",
    "        item for item, count in collections.Counter(samples).items() if count > 1\n",
    "    ]\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "def plink_bed_to_vcf(bed_file, bim_file, fam_file, fasta_file=None, out_prefix=None, snps_only=True, chr_prefix=True):\n",
    "    \"\"\"Converts PLINK .bed files to VCF format.\"\"\"\n",
    "    if out_prefix is None:\n",
    "        out_prefix = os.path.splitext(bed_file)[0]\n",
    "\n",
    "    logging.info(f\"Converting BED to VCF: {bed_file}, {bim_file}, {fam_file}\")\n",
    "\n",
    "    output_dir = os.path.dirname(out_prefix)\n",
    "    create_directory(output_dir)  # Ensure the directory exists\n",
    "\n",
    "    duplicates = check_duplicate_samples(fam_file)\n",
    "    if duplicates:\n",
    "        logging.error(f\"Duplicate sample names found: {duplicates}\")\n",
    "        return None\n",
    "\n",
    "    snps_only_option = \"--snps-only 'just-acgt'\" if snps_only else \"\"\n",
    "    chr_prefix_option = \"--output-chr chrM\" if chr_prefix else \"\"\n",
    "    fasta_option = f\"--ref-from-fa --fa {fasta_file}\" if fasta_file else \"\"\n",
    "\n",
    "    commands = [\n",
    "        f\"plink2 --bed {bed_file} --bim {bim_file} --fam {fam_file} --make-pgen --merge-x --sort-vars {snps_only_option} --out sorted\",\n",
    "        f\"plink2 --pfile sorted --export vcf id-paste=iid bgz {fasta_option} --out {out_prefix} {chr_prefix_option}\",\n",
    "        \"rm sorted.*\"\n",
    "    ]\n",
    "\n",
    "    for cmd in commands:\n",
    "        run_command(cmd)\n",
    "\n",
    "    vcf_path = f\"{out_prefix}.vcf.gz\"\n",
    "    if os.path.exists(vcf_path):\n",
    "        logging.info(f\"VCF file generated successfully: {vcf_path}\")\n",
    "        logging.info(f\"Starting indexing {vcf_path}\")\n",
    "        run_command(f\"bcftools index --threads 12 {vcf_path}\")\n",
    "        logging.info(f\"Indexing completed for VCF file: {vcf_path}\")\n",
    "    else:\n",
    "        logging.error(f\"Failed to generate VCF file at {vcf_path}\")\n",
    "        return None\n",
    "\n",
    "    return vcf_path\n",
    "\n",
    "\n",
    "def liftover_to_hg38(input_vcf, output_bcf, reject_bcf, src_fasta, ref_fasta, chain_file):\n",
    "    \"\"\"Performs liftover to hg38 using bcftools.\"\"\"\n",
    "    create_directory(os.path.dirname(output_bcf))  # Ensure output directory exists\n",
    "    create_directory(os.path.dirname(reject_bcf))  # Ensure reject directory exists\n",
    "    \n",
    "    command = (f\"bcftools +liftover --no-version -Ou {input_vcf} -- \"\n",
    "               f\"-s {src_fasta} -f {ref_fasta} -c {chain_file} --reject {reject_bcf} --write-src | \"\n",
    "               f\"bcftools sort -o {output_bcf} -Ob --write-index\")\n",
    "    success, message = run_command(command)\n",
    "    if success:\n",
    "        logging.info(f\"Liftover completed successfully for {input_vcf}\")\n",
    "        return output_bcf\n",
    "    else:\n",
    "        logging.error(f\"Liftover failed for {input_vcf}: {message}\")\n",
    "        return None\n",
    "\n",
    "# Note: Chromosome notation should follow the GRCh38/hg38 notations ('chr#' for autosomal chromosomes and 'chrX' for\n",
    "# chromosome 23). BUT you are using hg37 for this part as you havent lifted the build . perhaps run this after liftover as a check \n",
    "def create_frequency_files(vcf_path, dataset_prefix):\n",
    "    \"\"\"Creates frequency files from VCF using bcftools.\"\"\"\n",
    "    output_vcf = f\"{dataset_prefix}_AF.vcf.gz\"\n",
    "    freq_file = f\"{dataset_prefix}.frq\"\n",
    "    logging.info(f\"Creating frequency file for: {vcf_path}\")\n",
    "\n",
    "    commands = [\n",
    "        f\"bcftools +fill-tags {vcf_path} -Oz --threads 12 -o {output_vcf} -- -t AF\",\n",
    "        f\"bcftools query -f '%CHROM\\\\t%CHROM_%POS_%REF_%ALT\\\\t%REF\\\\t%ALT\\\\t%INFO/AF\\\\n' {output_vcf} | sed '1i\\\\\\nCHR\\\\tSNP\\\\tREF\\\\tALT\\\\tAF' > {freq_file}\"\n",
    "    ]\n",
    "\n",
    "    for cmd in commands:\n",
    "        success, message = run_command(cmd)\n",
    "        if not success:\n",
    "            logging.error(f\"Command failed: {cmd}\")\n",
    "            logging.error(message)\n",
    "            return None\n",
    "\n",
    "    return freq_file\n",
    "\n",
    "\n",
    "def analyze_frequency_files(\n",
    "    freq_file, ref_freq_file, dataset_prefix, af_diff_limit=0.1\n",
    "):\n",
    "    \"\"\"Analyzes frequency files to compare allele frequencies.\"\"\"\n",
    "    try:\n",
    "        # Ensure the delimiter is correctly specified, assuming tab-delimited files\n",
    "        freq_data = pd.read_csv(freq_file, sep=\"\\t\")\n",
    "        ref_data = pd.read_csv(ref_freq_file, sep=\"\\t\")\n",
    "\n",
    "        merged_data = pd.merge(\n",
    "            freq_data, ref_data, on=\"SNP\", suffixes=(\".chip\", \".ref\")\n",
    "        )\n",
    "        merged_data[\"AF_diff\"] = abs(merged_data[\"AF.chip\"] - merged_data[\"AF.ref\"])\n",
    "        high_diff_data = merged_data[merged_data[\"AF_diff\"] > af_diff_limit]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(\n",
    "            merged_data[\"AF.ref\"],\n",
    "            merged_data[\"AF.chip\"],\n",
    "            c=\"blue\",\n",
    "            label=\"Within Threshold\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "            high_diff_data[\"AF.ref\"],\n",
    "            high_diff_data[\"AF.chip\"],\n",
    "            c=\"red\",\n",
    "            label=\"Above Threshold\"\n",
    "        )\n",
    "        plt.xlabel(\"Reference Allele Frequency\")\n",
    "        plt.ylabel(\"Chip Allele Frequency\")\n",
    "        plt.title(f\"Allele Frequency Comparison for {dataset_prefix}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        output_image_path = f\"{dataset_prefix}_allele_frequency_comparison.png\"\n",
    "        plt.savefig(output_image_path)\n",
    "        logging.info(f\"Plot saved to {output_image_path}\")\n",
    "\n",
    "        # Display the plot if running in an interactive environment\n",
    "        plt.show()\n",
    "\n",
    "        return high_diff_data\n",
    "    except pd.errors.ParserError as e:\n",
    "        logging.error(f\"Error parsing CSV file: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in analyzing frequency files: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_config(config_path) -> dict:\n",
    "    \"\"\"Loads configuration from a YAML file.\"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "def process_batches(config):\n",
    "    \"\"\"Main processing workflow for genomic data.\"\"\"\n",
    "    batches = config['batches']\n",
    "    strand_files = config['strand_files']\n",
    "    rsid_files = config['rsid_files']\n",
    "    human_g1k_v37_path = config['human_g1k_v37_path']\n",
    "    GRCh37_path = config['GRCh37_path']\n",
    "    GRCh38_path = config['GRCh38_path']\n",
    "    chain_file = config['chain_file']\n",
    "\n",
    "    updated_batches = {batch: update_build(path, strand_files[batch], f\"data/1_updated/{batch}\")\n",
    "                       for batch, path in batches.items()}\n",
    "    \n",
    "    updated_rsids = {batch: update_rsids(updated_path, f\"data/2_updated_rsids/{batch}/{batch}\", rsid_files[batch])\n",
    "                     for batch, updated_path in updated_batches.items() if updated_path}\n",
    "    \n",
    "    removed_duplicates = {batch: remove_duplicate_samples(updated_path, f\"data/3_removed_duplicates/{batch}/{batch}_no_duplicates\")\n",
    "                          for batch, updated_path in updated_rsids.items() if updated_path}\n",
    "    \n",
    "    vcf_outputs = {batch: plink_bed_to_vcf(f\"{path}.bed\", f\"{path}.bim\", f\"{path}.fam\", fasta_file=GRCh37_path,\n",
    "                                           out_prefix=f\"data/4_vcf_outputs/{batch}/{batch}\")\n",
    "                   for batch, path in removed_duplicates.items() if path}\n",
    "\n",
    "    for batch, vcf_file in vcf_outputs.items():\n",
    "        if vcf_file:\n",
    "            create_frequency_files(vcf_file, f\"data/4_vcf_outputs/{batch}\")\n",
    "\n",
    "    frequency_plots = {batch: analyze_frequency_files(vcf_file, f\"data/reference_frequency/{batch}.frq\", \n",
    "                                                      f\"data/4_vcf_outputs/{batch}\", 0.1)\n",
    "                       for batch, vcf_file in vcf_outputs.items() if vcf_file}\n",
    "\n",
    "    frequency_plots = {batch: plot_data for batch, plot_data in frequency_plots.items() if plot_data is not None}\n",
    "    logging.info(f\"Frequency plots data: {frequency_plots}\")\n",
    "\n",
    "\n",
    "    liftover_outputs = {batch: liftover_to_hg38(vcf_file, os.path.join(f\"data/5_liftover/{batch}\", f\"{batch}.bcf\"),\n",
    "                                                os.path.join(f\"data/5_liftover/{batch}\", f\"{batch}_reject.bcf\"),\n",
    "                                                human_g1k_v37_path, GRCh38_path, chain_file)\n",
    "                        for batch, vcf_file in vcf_outputs.items() if vcf_file}\n",
    "    logging.info(f\"Liftover outputs: {liftover_outputs}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = load_config('config.yaml')\n",
    "    process_batches(config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GWAS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
